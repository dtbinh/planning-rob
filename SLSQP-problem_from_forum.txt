 

discussions related to NLopt nonlinear-optimization library ()
headers
schattenpflanze | 16 Feb 13:39 2011
 Picon 
Runtime errors for large gradients

<schattenpflanze@...>
2011-02-16 12:39:27 GMT
Hi,

I would like to support the request that Alexander Riess has posted on 
January 28. Just like him, I keep getting std::runtime_errors for large 
gradients. I am using the C++ library, not the Python interface. I could 
provide additional test cases, if necessary, but I suppose the simple 
example posted by Alexander already illustrates the problem very well.

Best regards,
Peter

> Thanks for the Bugfix.
>
> Today I am back with a class of new, but similar testproblems
>
>    min -s*x on [-1,1]
>
> with different s.
>
> Configuration:
>
> opt.set_lower_bounds( [-1.0 ] )
> opt.set_upper_bounds( [ 1.0 ] )
> opt.set_min_objective(f)
> opt.set_xtol_abs(1e-10)
> opt.set_xtol_rel(1e-10)
> opt.set_ftol_abs(1e-10)
> opt.set_ftol_rel(1e-10)
> x0   = array([0.0])
>
(Continue reading)

Permalink | Reply | 
headers
Steven G. Johnson | 7 Mar 21:58 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-07 20:58:39 GMT
Tracing through the code, this appears to be a problem in the original  
SLSQP software.  SLSQP works by minimizing an approximate quadratic  
subproblem at each step.  At the first step of Alexander's 1d test  
case, SLSQP is minimizing:

	min_x  (x - s)^2
                -1 <= x <= 1

which should give x = 1 for s > 0 -- i.e., it should converge in 1  
step.  However, for large s, SLSQP (in its subroutine LSQ) seems to be  
suffering from extremely large round-off errors, as if it were solving  
an ill-conditioned problem or if were using a numerically unstable  
algorithm.  I'm not sure why that should be the case here, however;  
the problem doesn't seem too badly conditioned even for s=1e6, and the  
QR algorithm that LSQ claims to be using should be stable, I think.   
For s=1e6 the LSQ routine is "solving" the above subproblem with  
x=-356.31518661149312, and that is screwing everything up in  
subsequent steps.

One thing that would be helpful would be if someone tried Alexander's  
test problem in fmin_slsqp from SciPy, which also uses the SLSQP code,  
to see if a similar problem (albeit probably with different symptoms)  
occurs there.

Unfortunately, the guts of the LSQ routine in SLSQP are rather painful  
to debug; this is pretty ugly spaghetti-style code (even before f2c  
conversion from Fortran to C), and this appears to be a roundoff  
susceptibility rather than a more straightforward bug.  It almost  
looks easier to rip it out completely and replace it with something  
LAPACK-based (i.e. based on modern linear algebra libraries), but that  
(Continue reading)

Permalink | Reply | 
headers
schattenpflanze | 8 Mar 10:29 2011
 Picon 
Re: Runtime errors for large gradients

<schattenpflanze@...>
2011-03-08 09:29:32 GMT
Dear Steven,

Thank you for investigating.

> One thing that would be helpful would be if someone tried Alexander's
> test problem in fmin_slsqp from SciPy, which also uses the SLSQP code,
> to see if a similar problem (albeit probably with different symptoms)
> occurs there.
Unfortunately, I cannot help you with that. I have no idea about Python.

> Tracing through the code, this appears to be a problem in the original
> SLSQP software. SLSQP works by minimizing an approximate quadratic
> subproblem at each step. At the first step of Alexander's 1d test case,
> SLSQP is minimizing:
>
> min_x (x - s)^2
> -1 <= x <= 1
I wonder whether this is really the problem actually solved by the 
method. I must admit, I have not checked the code, and I am not sure 
about SLSQP. The original problem is
min_x  f(x) = -s * x
g(x) = (x-1, -x-1)^T <= 0.
In a general SQP method, one would then solve
min_d  -s * d
(x_k - 1, -x_k - 1) + (d, -d) <=0,
where x_k is the previous iterate, and then set
x_{k+1} = x_k + d.
(Actually, one would perform a line search with Armijo rule and search 
direction d.)
There is no quadratic term in the target function in this case, since 
(Continue reading)

Permalink | Reply | 
headers
Steven G. Johnson | 8 Mar 17:25 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-08 16:25:35 GMT

On Mar 8, 2011, at 4:29 AM, schattenpflanze@... wrote:
>> Tracing through the code, this appears to be a problem in the  
>> original
>> SLSQP software. SLSQP works by minimizing an approximate quadratic
>> subproblem at each step. At the first step of Alexander's 1d test  
>> case,
>> SLSQP is minimizing:
>>
>> min_x (x - s)^2
>> -1 <= x <= 1
> I wonder whether this is really the problem actually solved by the  
> method. I must admit, I have not checked the code, and I am not sure  
> about SLSQP. The original problem is
> min_x  f(x) = -s * x
> g(x) = (x-1, -x-1)^T <= 0.
> In a general SQP method, one would then solve
> min_d  -s * d

You need to realize that SLSQP is a quasi-Newton method, not a Newton  
method: it is sequential quadratic programming with an *approximate*  
Hessian (2nd derivative) that is built up iteratively.

That is, at each step, it solves a quadratic approximation of the  
original objective, where the linear term is the gradient and the  
quadratic term is an approximate Hessian.   The Hessian is constructed  
from BFGS updates, based on the gradients and function values at  
subsequent steps, and like any BFGS method it only approaches the true  
Hessian in the limit of many iterations near a minimum.

(Continue reading)

Permalink | Reply | 
headers
Alexander Riess | 14 Mar 11:50 2011
Re: Runtime errors for large gradients

Alexander Riess <rie.uoa@...>
2011-03-14 10:50:07 GMT
Hi

> One thing that would be helpful would be if someone tried Alexander's  
> test problem in fmin_slsqp from SciPy, which also uses the SLSQP code,  
> to see if a similar problem (albeit probably with different symptoms)  
> occurs there.

I tried to solve the test-problem min -s*x on [-1.0,1.0] with SciPy. The 
summary, program and results are listed bellow.

If 1.0 <= s <= 100 everything works fine: Optimization terminated 
successfully. If s > 1.0E2 the result is: Positive directional derivative for 
linesearch. If s > 1.0E5 the calculated value of xmin is wrong: [0.0].

Summary:
------------------------------------------------------------------------

s = 1.0E0: [[1.0], -1.0, 2, 0, 'Optimization terminated successfully.']
s = 1.0E1: [[1.0000000000000924], -10.000000000000924, 2, 0, 'Optimization 
terminated successfully.']
s = 1.0E2: [[0.99999999977386267], -99.999999977386267, 2, 0, 'Optimization 
terminated successfully.']
s = 1.0E3: [[0.99999982147039645], -999.99982147039645, 6, 8, 'Positive 
directional derivative for linesearch']
s = 1.0E4: [[0.99987339457766211], -9998.7339457766211, 7, 8, 'Positive 
directional derivative for linesearch']
s = 1.0E5: [[1.1326320648076944], -113263.20648076944, 7, 8, 'Positive 
directional derivative for linesearch']
s = 1.0E6: [[0.0], -0.0, 5, 8, 'Positive directional derivative for 
linesearch']
(Continue reading)

Permalink | Reply | 
headers
Steven G. Johnson | 14 Mar 12:55 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-14 11:55:30 GMT

On Mar 14, 2011, at 6:50 AM, Alexander Riess wrote:
>> One thing that would be helpful would be if someone tried Alexander's
>> test problem in fmin_slsqp from SciPy, which also uses the SLSQP  
>> code,
>> to see if a similar problem (albeit probably with different symptoms)
>> occurs there.
>
> I tried to solve the test-problem min -s*x on [-1.0,1.0] with SciPy.  
> The
> summary, program and results are listed bellow.
>
> If 1.0 <= s <= 100 everything works fine: Optimization terminated
> successfully. If s > 1.0E2 the result is: Positive directional  
> derivative for
> linesearch. If s > 1.0E5 the calculated value of xmin is wrong: [0.0].

Thanks for checking on this; this confirms that the problem is in the  
original SLSQP, and not in some mistake I made in porting it.

Steven

Permalink | Reply | 
headers
Alexander Riess | 15 Mar 07:17 2011
Re: Runtime errors for large gradients

Alexander Riess <rie.uoa@...>
2011-03-15 06:17:34 GMT
Hi

> One thing that would be helpful would be if someone tried Alexander's  
> test problem in fmin_slsqp from SciPy, which also uses the SLSQP code,  
> to see if a similar problem (albeit probably with different symptoms)  
> occurs there.

I used SciPy to solve the problem min -s*x on [-1;1] with fmin_slsqp. 

Fmin_slsqp fails to solve the problem for s >= 1.0E6. If s >= 1.0E3 the result 
code is 'Positive directional derivative for linesearch'.

Below the results and program is listed.

Kind regards

Alexander Riess

Results:
-------------------------------------------------------------------------

Optimization of -s*x on [-1.0,1.0] using fmin_slsqp | s =  1.0
==============================================================
  NIT    FC           OBJFUN            GNORM
    1     1    -0.000000E+00     1.000000E+00
    2     2    -1.000000E+00     1.000000E+00
Optimization terminated successfully.    (Exit mode 0)
            Current function value: -1.0
            Iterations: 2
            Function evaluations: 2
(Continue reading)

Permalink | Reply | 
headers
schattenpflanze | 8 Mar 18:07 2011
 Picon 
Re: Runtime errors for large gradients

<schattenpflanze@...>
2011-03-08 17:07:57 GMT
> You need to realize that SLSQP is a quasi-Newton method, not a Newton
> method: it is sequential quadratic programming with an *approximate*
> Hessian (2nd derivative) that is built up iteratively.
> [snip]
> In particular, for the very first step the Hessian is initialized to the
> identity matrix (divided by 2)
You are, of course, right. Thanks for pointing this out.

> SLSQP is a BFGS method.
> So, if you have no nonlinear constraints I'm not sure why SLSQP would
> converge significantly differently than any of the other quasi-Newton
> methods.
I agree with that. In the NLopt implementation, however, SLSQP seems to
perform a line search, while LBFGS does not (?). LBFGS evaluates the
gradient every time the function is called. This also affects
convergence. For a very small, randomly picked test with my application,
I obtain the following results:
SLSQP: 54 gradients, 100 function evaluations, 28 seconds,
LBFGS: 116 gradients, 116 function evaluations, 67 seconds.
Perhaps, I am missing something here? According to the manual, the
gradient is required if and only if the gradient is not empty().

Apart from that, I would love to see the SQP method being reliable and
stable for all cases. At some point, I will have to add non-linear
constraints to my problem and then SQP will definitely be the method of
choice.

Best regards,
Peter

(Continue reading)

Permalink | Reply | 
headers
Steven G. Johnson | 8 Mar 18:46 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-08 17:46:36 GMT

On Mar 8, 2011, at 12:07 PM, schattenpflanze@... wrote:
> I agree with that. In the NLopt implementation, however, SLSQP seems  
> to
> perform a line search, while LBFGS does not (?). LBFGS evaluates the
> gradient every time the function is called. This also affects
> convergence. For a very small, randomly picked test with my  
> application,
> I obtain the following results:
> SLSQP: 54 gradients, 100 function evaluations, 28 seconds,
> LBFGS: 116 gradients, 116 function evaluations, 67 seconds.
> Perhaps, I am missing something here? According to the manual, the
> gradient is required if and only if the gradient is not empty().

They both perform line searches (essentially any quasi-Newton method  
must do this), but you are right in that SLSQP's line-search  
implementation tries to avoid evaluating the gradient if it does not  
need it.  (The gradient is needed only for the first and last step of  
the line search.)

It probably wouldn't be too hard to modify the LBFGS implementation to  
do something similar.

Steven

PS. You can probably save a few more function evaluations if you check  
for repeated calls with the same arguments.  The reason is that, on  
the line search, SLSQP often calls your function twice at the end of  
the line search: once without the gradient, and then once more (when  
it realizes ex post facto that the line search is done) with the  
(Continue reading)

Permalink | Reply | 
headers
schattenpflanze | 8 Mar 20:05 2011
 Picon 
Re: Runtime errors for large gradients

<schattenpflanze@...>
2011-03-08 19:05:17 GMT
> PS. You can probably save a few more function evaluations if you
> check for repeated calls with the same arguments. The reason is
> that, on the line search, SLSQP often calls your function twice at
> the end of the line search: once without the gradient, and then once
> more (when it realizes ex post facto that the line search is done)
> with the gradient.
Yes, I have noticed that. Unfortunately, I cannot make use of
this fact. I use automatic differentiation for the gradients, so
computing the derivative involves computing the function anyway.

> An alternative interface would be to have separate function calls for
> the objective and its gradient, but this is problematic because the
> value and gradient usually share many calculations.
Exactly! I think the interface is perfect as is, given that the gradient 
computation is really avoided whenever possible.

In fact, for realistic parameter sets, computing the gradients (with
some automatic differentiation data type) consumes about 90% of the
total runtime of my program. Evaluating the function without 
differentiation (data type double) is quite cheap.

> It probably wouldn't be too hard to modify the LBFGS implementation
> to do something similar.
That would be great! Perhaps LBFGS would be competitive then (as long as
I have no non-linear constraints).

Best regards,
Peter

(Continue reading)

Permalink | Reply | 
headers
Gregory Maxwell | 8 Mar 20:14 2011
 Picon 
Re: Runtime errors for large gradients

Gregory Maxwell <gmaxwell@...>
2011-03-08 19:14:28 GMT
On Tue, Mar 8, 2011 at 2:05 PM,  <schattenpflanze <at> arcor.de> wrote:
>> PS. You can probably save a few more function evaluations if you
>> check for repeated calls with the same arguments. The reason is
>> that, on the line search, SLSQP often calls your function twice at
>> the end of the line search: once without the gradient, and then once
>> more (when it realizes ex post facto that the line search is done)
>> with the gradient.
>
> Yes, I have noticed that. Unfortunately, I cannot make use of
> this fact. I use automatic differentiation for the gradients, so
> computing the derivative involves computing the function anyway.

Perhaps a dumb question— but why are you using automatic differentiation
instead of using a gradient free algorithm?

Are the gradient free algorithims in NLOPT really so poor for your
application that
automatic differentiation + a with-gradient algorithm is superior?

_______________________________________________
NLopt-discuss mailing list
NLopt-discuss <at> ab-initio.mit.edu
http://ab-initio.mit.edu/cgi-bin/mailman/listinfo/nlopt-discuss
Permalink | Reply | 
headers
Steven G. Johnson | 8 Mar 20:49 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-08 19:49:25 GMT

On Mar 8, 2011, at 2:14 PM, Gregory Maxwell wrote:

> On Tue, Mar 8, 2011 at 2:05 PM,  <schattenpflanze@...> wrote:
>>> PS. You can probably save a few more function evaluations if you
>>> check for repeated calls with the same arguments. The reason is
>>> that, on the line search, SLSQP often calls your function twice at
>>> the end of the line search: once without the gradient, and then once
>>> more (when it realizes ex post facto that the line search is done)
>>> with the gradient.
>>
>> Yes, I have noticed that. Unfortunately, I cannot make use of
>> this fact. I use automatic differentiation for the gradients, so
>> computing the derivative involves computing the function anyway.
>
> Perhaps a dumb question— but why are you using automatic  
> differentiation
> instead of using a gradient free algorithm?
>
> Are the gradient free algorithims in NLOPT really so poor for your
> application that
> automatic differentiation + a with-gradient algorithm is superior?

Assuming Peter is using standard terminology, automatic  
differentiation does *not* mean numerical differentiation with finite  
differences.  Automatic differentiation means calculating the exact  
derivative analytically, just using a computer program rather than  
doing it by hand: an AD differentiaties your source code symbolically.

So, automatic differentiation can in principle be the same efficiency  
(Continue reading)

Permalink | Reply | 
headers
Gregory Maxwell | 8 Mar 20:53 2011
 Picon 
Re: Runtime errors for large gradients

Gregory Maxwell <gmaxwell@...>
2011-03-08 19:53:20 GMT
On Tue, Mar 8, 2011 at 2:49 PM, Steven G. Johnson <stevenj.mit <at> gmail.com> wrote:
> Assuming Peter is using standard terminology, automatic differentiation does
> *not* mean numerical differentiation with finite differences.  Automatic
> differentiation means calculating the exact derivative analytically, just
> using a computer program rather than doing it by hand: an AD differentiaties
> your source code symbolically.
>
> So, automatic differentiation can in principle be the same efficiency as
> programming analytical derivatives by hand, and with it the gradient-based
> algorithms are probably far superior to the derivative-free algorithms for
> this many unknowns.
>
> In principle, since AD takes source code to compute an objective and
> generates source code to compute objective+gradient, you could possibly edit
> the resulting code to remove stuff only needed for the computation of the
> objective.  But editing program-generated code by hand is messy, and is
> fragile because you need to re-do it each time you change your objective, so
> I can understand why Peter wouldn't want to do it.

Ah, duh, I was tunnel visioned on finite differences because of the
statements that the differentiation was very expensive compared to the
objective and that 'computing the derivative involves computing the
function'.

Don't mind me. :)

_______________________________________________
NLopt-discuss mailing list
NLopt-discuss <at> ab-initio.mit.edu
http://ab-initio.mit.edu/cgi-bin/mailman/listinfo/nlopt-discuss
(Continue reading)

Permalink | Reply | 
headers
Steven G. Johnson | 8 Mar 20:58 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-08 19:58:34 GMT

On Mar 8, 2011, at 2:05 PM, schattenpflanze@... wrote:
> In fact, for realistic parameter sets, computing the gradients (with
> some automatic differentiation data type) consumes about 90% of the
> total runtime of my program. Evaluating the function without  
> differentiation (data type double) is quite cheap.

Peter, this probably means that your automatic differentiation program  
is poor for this kind of problem.

There is a theorem that you can always compute the gradient of f(x)  
(any function from R^n to R) with about as many additional operations  
as are required to compute f(x) **once**.   The technique for doing so  
is called an "adjoint method", or "reverse accumulation".

So you want an AD program that advertises "reverse mode"  
differentiation or something similar.

In contrast, AD programs that use "forward mode" or "forward  
accumulation" differentiation are poor for differentiating multi- 
variate functions (R^n to R), since they have cost that grows  
proportional to n.  (Forward accumulation is good for differentiating  
functions from R to R^m.)

Steven

Permalink | Reply | 
headers
schattenpflanze | 9 Mar 09:54 2011
 Picon 
Re: Runtime errors for large gradients

<schattenpflanze@...>
2011-03-09 08:54:38 GMT
> Assuming Peter is using standard terminology, automatic
> differentiation does *not* mean numerical differentiation with finite
> differences.  Automatic differentiation means calculating the exact
> derivative analytically, just using a computer program rather than
> doing it by hand: an AD differentiaties your source code
> symbolically.
Yes, that is precisely what I do.

> There is a theorem that you can always compute the gradient of f(x)
> (any function from R^n to R) with about as many additional operations
> as are required to compute f(x) **once**. The technique for doing so
> is called an "adjoint method", or "reverse accumulation".
I do use a library which allows for reverse accumulation (namely CppAD),
and I think it is quite efficient. In particular, it usually requires 
only a constant factor of additional computational time compared to the
function evaluation. This factor is roughly equal to 10 in my case.
The overhead is due to the fact that all arithmetic operations have to
be recorded to a 'tape' first, Taylor coefficients are computed and
propagated, and then an additional reverse sweep is performed. By
design, the function has to be evaluated before any differentiation can
be done.

Furthermore, CppAD works by overloading functions with a different data 
type, not by code generation. This is essential, since my functions 
contain external templated libraries relying on (large amounts of) 
conditional expressions. Thus, the function I differentiate actually 
varies with the parameters. Differentiating once and for all, which is 
usually the goal of AD, does not work.

So, while a factor of 10 is great compared to the factor of 50 or even 
(Continue reading)

Permalink | Reply | 
headers
Steven G. Johnson | 9 Mar 17:00 2011
 Picon 
Re: Runtime errors for large gradients

Steven G. Johnson <stevenj.mit@...>
2011-03-09 16:00:42 GMT

On Mar 9, 2011, at 3:54 AM, schattenpflanze@... wrote:
> Furthermore, CppAD works by overloading functions with a different  
> data type, not by code generation.

Ah, that's why it is slow.

> For 50 variables in a non-linear problem, gradient-free methods will  
> perhaps never converge.

There are many gradient-free methods that are provably convergent (for  
sufficiently smooth functions); this is not a general weakness of  
gradient-free methods.

(The notorious counterexample is Nelder-Mead, but to be fair there  
have also been historical gradient-based methods that were  
subsequently found to not converge in certain cases.)

Steven

Permalink | Reply | 
Return
Return to gmane.science.analysis.nlopt.general.
Advertisement
Project Web Page
discussions related to NLopt nonlinear-optimization library ()
Search Archive


Language
Change language
Options
Current view: Threads only / Showing only 20 lines / Not hiding cited text.
Change to All messages, whole messages, or hide cited text.

Post a message
NNTP Newsgroup
Classic Gmane web interface
XML RSS Feed
List Information

About Gmane

Gmane
